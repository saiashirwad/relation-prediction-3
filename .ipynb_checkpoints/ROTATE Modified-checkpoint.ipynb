{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD \n",
    "\n",
    "from torch_scatter import scatter \n",
    "from torchkge.utils.datasets import load_fb15k237\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import os \n",
    "\n",
    "from layers import * \n",
    "from loss import * \n",
    "from evaluation import * \n",
    "from utils import * \n",
    "from dataloader import * \n",
    "from rotate import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openke\n",
    "from openke.config import Trainer, Tester\n",
    "from openke.module.model import RotatE\n",
    "from openke.module.loss import SigmoidLoss\n",
    "from openke.module.strategy import NegativeSampling\n",
    "from openke.data import TrainDataLoader, TestDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sample_size = 10\n",
    "batch_size = 1000\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sai/code/relation-prediction-3/data/FB15k-237\"\n",
    "with open(os.path.join(data_path, 'entities.dict')) as fin:\n",
    "    entity2id = dict()\n",
    "    for line in fin:\n",
    "        eid, entity = line.strip().split('\\t')\n",
    "        entity2id[entity] = int(eid)\n",
    "\n",
    "with open(os.path.join(data_path, 'relations.dict')) as fin:\n",
    "    relation2id = dict()\n",
    "    for line in fin:\n",
    "        rid, relation = line.strip().split('\\t')\n",
    "        relation2id[relation] = int(rid)\n",
    "\n",
    "n_ent = len(entity2id)\n",
    "n_rel = len(relation2id)\n",
    "\n",
    "train_triplets = read_triple(os.path.join(data_path, 'train.txt'), entity2id, relation2id)\n",
    "valid_triplets = read_triple(os.path.join(data_path, 'valid.txt'), entity2id, relation2id)\n",
    "test_triplets = read_triple(os.path.join(data_path, 'test.txt'), entity2id, relation2id)\n",
    "\n",
    "all_true_triplets = train_triplets + valid_triplets + test_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_head = DataLoader(\n",
    "    TrainDataset(train_triplets, n_ent, n_rel, negative_sample_size, 'head-batch'), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    collate_fn=TrainDataset.collate_fn\n",
    ")\n",
    "\n",
    "train_dataloader_tail = DataLoader(\n",
    "    TrainDataset(train_triplets, n_ent, n_rel, negative_sample_size, 'tail-batch'), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    collate_fn=TrainDataset.collate_fn\n",
    ")\n",
    "\n",
    "train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_embed = torch.randn(n_ent, 100)\n",
    "rel_embed = torch.randn(n_rel, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sample, negative_sample, subsampling_weight, mode = next(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 3]),\n",
       " torch.Size([1000, 10]),\n",
       " torch.Size([1000]),\n",
       " 'tail-batch')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample.shape, negative_sample.shape, subsampling_weight.shape, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = positive_sample.repeat((11, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr[1000:, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[1000:, 2] = negative_sample.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"tail-batch\":\n",
    "    head_part = positive_sample\n",
    "    tail_part = negative_sample\n",
    "else:\n",
    "    head_part = negative_sample\n",
    "    tail_part = positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 3]), torch.Size([1000, 10]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_part.shape, tail_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = torch.index_select(ent_embed, dim=0, index=head_part[:, 0]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation = torch.index_select(rel_embed, dim=0, index=head_part[:, 1]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1, 100]), torch.Size([1000, 1, 50]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.shape, relation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = torch.index_select(ent_embed, dim=0, index=tail_part.view(-1)).view(batch_size, negative_sample_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_head, im_head = torch.chunk(head, 2, dim=2)\n",
    "re_tail, im_tail = torch.chunk(tail, 2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_relation = relation / (5.0 / 3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_relation = torch.cos(phase_relation)\n",
    "im_relation = torch.cos(phase_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_score = re_head * re_relation - im_head * im_relation\n",
    "im_score = re_head * im_relation + im_head * re_relation\n",
    "\n",
    "re_score = re_score - re_tail \n",
    "im_score = im_score - im_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.stack([re_score, im_score], dim=0).norm(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10, 50])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.sum(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer to work with RotAtt\n",
    "class Trainer:\n",
    "    def __init__(self, name, model: nn.Module, dataset=\"FB15k-237\", n_epochs=1000, batch_size=2000, device=\"cuda\", \n",
    "        optim_ = \"sgd\", lr = 0.001, checkpoint_dir=\"checkpoints\"):\n",
    "        self.name = name\n",
    "        \n",
    "        self.work_threads = 4 \n",
    "        self.lr = lr \n",
    "        self.weight_decay = None\n",
    "\n",
    "        self.n_epochs = n_epochs\n",
    "        self.device = device\n",
    "        \n",
    "        self.model = model\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr)\n",
    "        \n",
    "        self.adversarial_temperature = 1.0\n",
    "\n",
    "        self.negative_sample_size = 10\n",
    "        \n",
    "        self.load_data(dataset)\n",
    "        \n",
    "        train_dataloader_head = DataLoader(\n",
    "            TrainDataset(self.train_triplets, self.n_ent, self.n_rel, self.negative_sample_size, 'head-batch'), \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True, \n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        train_dataloader_tail = DataLoader(\n",
    "            TrainDataset(self.train_triplets, self.n_ent, self.n_rel, self.negative_sample_size, 'tail-batch'), \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True, \n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "        self.train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)\n",
    "        \n",
    "    def load_data(self, name):\n",
    "        data_path = f\"/home/sai/code/relation-prediction-3/data/{name}\"\n",
    "        with open(os.path.join(data_path, 'entities.dict')) as fin:\n",
    "            entity2id = dict()\n",
    "            for line in fin:\n",
    "                eid, entity = line.strip().split('\\t')\n",
    "                entity2id[entity] = int(eid)\n",
    "\n",
    "        with open(os.path.join(data_path, 'relations.dict')) as fin:\n",
    "            relation2id = dict()\n",
    "            for line in fin:\n",
    "                rid, relation = line.strip().split('\\t')\n",
    "                relation2id[relation] = int(rid)\n",
    "\n",
    "        self.n_ent = len(entity2id)\n",
    "        self.n_rel = len(relation2id)\n",
    "\n",
    "        self.train_triplets = read_triple(os.path.join(data_path, 'train.txt'), entity2id, relation2id)\n",
    "        self.valid_triplets = read_triple(os.path.join(data_path, 'valid.txt'), entity2id, relation2id)\n",
    "        self.test_triplets = read_triple(os.path.join(data_path, 'test.txt'), entity2id, relation2id)\n",
    "\n",
    "        all_true_triplets = train_triplets + valid_triplets + test_triplets\n",
    "\n",
    "    \n",
    "    def train_one_step(self):\n",
    "        self.model.train() \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        positive_sample, negative_sample, subsampling_weight, mode = next(self.train_iterator)\n",
    "        positive_sample.to(self.device)\n",
    "        negative_sample.to(self.device)\n",
    "        subsampling_weight.to(self.device)\n",
    "        \n",
    "        triplets = positive_sample.repeat((self.negative_sample_size + 1, 1))\n",
    "        triplets[self.batch_size:, 2] = negative_sample.flatten()\n",
    "        \n",
    "        negative_score = (F.softmax(negative_score * self.adversarial_temperature, dim = 1).detach() \n",
    "                              * F.logsigmoid(-negative_score)).sum(dim = 1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def run(self, max_steps=10000):\n",
    "        self.model.train()\n",
    "        for step in range(max_steps):\n",
    "            self.train_one_step()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for epoch in training_range:\n",
    "#             res = 0\n",
    "#             for batch in self.dataloader_train:\n",
    "#                 triplets = torch.stack(batch)\n",
    "#                 triplets, _ = negative_sampling(triplets, self.n_ent, self.negative_rate)\n",
    "#                 triplets = triplets.to(self.device)\n",
    "\n",
    "#                 loss = self.train_one_step(triplets, \"tail\")\n",
    "#                 res += loss \n",
    "#             training_range.set_description(\"Epoch %d | loss: %f\" % (epoch, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotAttLayer(nn.Module):\n",
    "    def __init__(self, n_entities, n_relations, in_dim, out_dim, input_drop=0.5, \n",
    "                 margin=6.0, epsilon=2.0, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_entities = n_entities\n",
    "        self.n_relations = n_relations\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.margin = margin \n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.a = nn.Linear(3 * in_dim, out_dim).to(device)\n",
    "        nn.init.xavier_normal_(self.a.weight.data, gain=1.414)\n",
    "\n",
    "        self.a_2 = nn.Linear(out_dim, 1).to(device)\n",
    "        nn.init.xavier_normal_(self.a_2.weight.data, gain=1.414)\n",
    "\n",
    "        self.sparse_neighborhood_aggregation = SparseNeighborhoodAggregation()\n",
    "        \n",
    "        self.ent_embed_range = nn.Parameter(\n",
    "            torch.Tensor([(self.margin + self.epsilon) / self.out_dim]), \n",
    "            requires_grad = False\n",
    "        )\n",
    "        \n",
    "        self.rel_embed_range = nn.Parameter(\n",
    "            torch.Tensor([(self.margin + self.epsilon) / self.out_dim]),\n",
    "            requires_grad = False\n",
    "        )\n",
    "\n",
    "        self.ent_embed = nn.Embedding(n_entities, in_dim, max_norm=1, norm_type=2).to(device)\n",
    "        self.rel_embed = nn.Embedding(n_relations, in_dim, max_norm=1, norm_type=2).to(device)\n",
    "        \n",
    "        nn.init.uniform_(self.ent_embed.weight.data, -self.ent_embed_range.item(), self.ent_embed_range.item())\n",
    "        nn.init.uniform_(self.rel_embed.weight.data, -self.rel_embed_range.item(), self.rel_embed_range.item())\n",
    "\n",
    "        self.input_drop = nn.Dropout(input_drop)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm1d(3 * in_dim).to(device)\n",
    "        self.bn1 = nn.BatchNorm1d(out_dim).to(device)\n",
    "        \n",
    "    def forward(self, triplets, eval=False, mode=\"head\"):\n",
    "\n",
    "        N = self.n_entities\n",
    "        n = len(triplets)\n",
    "\n",
    "        h = torch.cat((\n",
    "            self.ent_embed(triplets[:, 0]),\n",
    "            self.ent_embed(triplets[:, 1]),\n",
    "            self.rel_embed(triplets[:, 2])\n",
    "        ), dim=1)\n",
    "        h_ = torch.cat((\n",
    "            self.ent_embed(triplets[:, 1]),\n",
    "            self.ent_embed(triplets[:, 0]),\n",
    "            -self.rel_embed(triplets[:, 2])\n",
    "        ), dim=1)\n",
    "\n",
    "        h = torch.cat((h, h_))\n",
    "\n",
    "        h = self.input_drop(self.bn0(h))\n",
    "        c = self.bn1(self.a(h))\n",
    "        b = -F.leaky_relu(self.a_2(c))\n",
    "        e_b = torch.exp(b)\n",
    "\n",
    "        temp = triplets.t()\n",
    "        edges = torch.stack((\n",
    "            torch.cat([temp[0], temp[1]]),\n",
    "            torch.cat([temp[1], temp[0]])\n",
    "        ))\n",
    "\n",
    "        ebs = self.sparse_neighborhood_aggregation(edges, e_b, N, e_b.shape[0], 1)\n",
    "        temp1 = e_b * c\n",
    "\n",
    "        hs = self.sparse_neighborhood_aggregation(edges, temp1,  N, e_b.shape[0], self.out_dim)\n",
    "\n",
    "        ebs[ebs == 0] = 1e-12\n",
    "        h_ent = hs / ebs\n",
    "\n",
    "        index = triplets[:, 2]\n",
    "        h_rel  = scatter(temp1[ : temp1.shape[0]//2, :], index=index, dim=0, reduce=\"mean\") \n",
    "        # h_rel_ =  scatter(temp1[temp1.shape[0]//2 : , :], index=index, dim=0, reduce=\"mean\")\n",
    "\n",
    "        return h_ent, h_rel\n",
    "class RotAtt(nn.Module):\n",
    "    def __init__(self, n_ent, n_rel, in_dim, out_dim, n_heads=1, input_drop=0.5, negative_rate = 10, margin=6.0, epsilon=2.0, device=\"cuda\"):\n",
    "        super().__init__() \n",
    "\n",
    "        self.n_heads = n_heads \n",
    "        self.device = device\n",
    "\n",
    "        self.in_dim = in_dim \n",
    "        self.out_dim = out_dim \n",
    "        self.margin = margin\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.a = nn.ModuleList([\n",
    "            RotAttLayer(\n",
    "                n_ent, n_rel, in_dim, out_dim, input_drop, margin=margin, epsilon=epsilon\n",
    "            )\n",
    "        for _ in range(self.n_heads)])\n",
    "\n",
    "        self.ent_transform = nn.Linear(n_heads * out_dim, out_dim).to(device)\n",
    "        self.rel_transform = nn.Linear(n_heads * out_dim, out_dim // 2).to(device)\n",
    "\n",
    "        \n",
    "        self.ent_embed_range = nn.Parameter(\n",
    "            torch.Tensor([(self.margin + self.epsilon) / self.out_dim]), \n",
    "            requires_grad = False\n",
    "        )\n",
    "        \n",
    "        self.rel_embed_range = nn.Parameter(\n",
    "            torch.Tensor([(self.margin + self.epsilon) / self.out_dim]),\n",
    "            requires_grad = False\n",
    "        )\n",
    "\n",
    "        self.pi = nn.Parameter(torch.Tensor([3.14159265358979323846])).to(device)\n",
    "        self.pi.detach()\n",
    "\n",
    "        self.negative_rate = negative_rate\n",
    "\n",
    "    def rotate(self, triplets, ent_embed, rel_embed, mode=\"head_batch\"):\n",
    "        \n",
    "        h = ent_embed[triplets[:, 0]]\n",
    "        t = ent_embed[triplets[:, 1]]\n",
    "        r  = rel_embed[triplets[:, 2]]\n",
    "\n",
    "        pi = self.pi\n",
    "\n",
    "        re_head, im_head = torch.chunk(h, 2, dim=-1)\n",
    "        re_tail, im_tail = torch.chunk(t, 2, dim=-1)\n",
    "\n",
    "        phase_relation = r / (self.rel_embed_range.item() / pi)\n",
    "\n",
    "        re_relation = torch.cos(phase_relation)\n",
    "        im_relation = torch.sin(phase_relation)\n",
    "\n",
    "        re_head = re_head.view(-1, re_relation.shape[0], re_head.shape[-1]).permute(1, 0, 2)\n",
    "        re_tail = re_tail.view(-1, re_relation.shape[0], re_tail.shape[-1]).permute(1, 0, 2)\n",
    "        im_head = im_head.view(-1, re_relation.shape[0], im_head.shape[-1]).permute(1, 0, 2)\n",
    "        im_tail = im_tail.view(-1, re_relation.shape[0], im_tail.shape[-1]).permute(1, 0, 2)\n",
    "        im_relation = im_relation.view(-1, re_relation.shape[0], im_relation.shape[-1]).permute(1, 0, 2)\n",
    "        re_relation = re_relation.view(-1, re_relation.shape[0], re_relation.shape[-1]).permute(1, 0, 2)\n",
    "\n",
    "        if mode == \"head_batch\":\n",
    "            re_score = re_relation * re_tail + im_relation * im_tail\n",
    "            im_score = re_relation * im_tail - im_relation * re_tail\n",
    "            re_score = re_score - re_head\n",
    "            im_score = im_score - im_head\n",
    "        else:\n",
    "            re_score = re_head * re_relation - im_head * im_relation\n",
    "            im_score = re_head * im_relation + im_head * re_relation\n",
    "            re_score = re_score - re_tail\n",
    "            im_score = im_score - im_tail\n",
    "\n",
    "        score = torch.stack([re_score, im_score], dim = 0)\n",
    "        score = score.norm(dim = 0).sum(dim = -1)\n",
    "        return score.permute(1, 0).flatten()\n",
    "\n",
    "    def forward(self, triplets, mode=\"tail_batch\", eval_=False):\n",
    "        n = len(triplets)\n",
    "\n",
    "        out = [a(triplets) for a in self.a]\n",
    "\n",
    "        ent_embed = self.ent_transform(torch.cat([o[0] for o in out], dim=1))\n",
    "        rel_embed = self.rel_transform(torch.cat([o[1] for o in out], dim=1))\n",
    "\n",
    "        if eval_ == False:\n",
    "            pos_triplets = triplets[:n // (self.negative_rate + 1)]\n",
    "            pos_triplets = torch.cat([pos_triplets for _ in range(self.negative_rate)])\n",
    "            neg_triplets = triplets[n // (self.negative_rate + 1) :]\n",
    "\n",
    "            pos_score = self.margin - self.rotate(pos_triplets, ent_embed, rel_embed, mode)\n",
    "            neg_score = self.margin - self.rotate(neg_triplets, ent_embed, rel_embed, mode)\n",
    "\n",
    "            y = torch.ones(len(pos_triplets)).to(self.device)\n",
    "\n",
    "            loss_fn = nn.MarginRankingLoss(margin=self.margin).to(self.device)\n",
    "            loss = loss_fn(pos_score, neg_score, y)\n",
    "\n",
    "            return loss \n",
    "        \n",
    "        else:\n",
    "            print(\"yep\")\n",
    "            # return self.margin - self.rotate(triplets, ent_embed, rel_embed, mode) \n",
    "            return ent_embed, rel_embed\n",
    "\n",
    "    def predict(self, data, mode=\"tail_batch\"):\n",
    "        score = -self.forward(data, mode, eval=True)\n",
    "        return score.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
